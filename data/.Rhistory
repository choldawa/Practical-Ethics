default_rate)
sum(dr*race_rates)/sum(race_rates) # in case we dont have it sum to 1
}
# find constant thresholds
find.constant.thresholds = function(def.limit){
t = uniroot(function(t){
default_rate_total(rep(t, 4))-def.limit
},
lower=300,
upper=850)$root
rep(t, 4)
}
# find constant conditional probability
find.equal.thresholds = function(def.limit){
p = uniroot(function(p){
default_rate_total(qnorm(1-p, race_means, race_sds))-def.limit},
lower=0.001,
upper=0.999)$root
qnorm(1-p, race_means, race_sds)
}
# find threshold for interpolated p
thresholds_p1 = find.equal.thresholds(def.limit)
deltas = thresholds_p1 - mean(thresholds_p1)
find.interp.thresholds = function(p, def.limit){
mu = uniroot(function(mu){
thresholds = deltas*p + mu
default_rate_total(thresholds)-def.limit
}, lower=300,
upper=850)$root
mu+deltas*p
}
#Find approval percent
slider_start = -30
slider_end = slider_start+170
p_list = seq(slider_start, slider_end, by = 1)
out = matrix(ncol = length(find.interp.thresholds(0.5, def.limit)),
nrow = length(p_list))
for (p in p_list){
for(i in 1:length(race_means))
out[(p-(slider_start-1)),i] = round((1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))*100,0)
#out[p+1,i] = (1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))
}
df = data.frame(out)
df$mu = rowMeans(df[,1:4])
colnames(df) = c('g1','g2','g3','g4', 'mu')
df$tradeoff = mu_type
df$p = p_list
out.json = toJSON(df, pretty = T)
write(out.json, "./FICOTest.json")
df = df %>% gather(key = 'race', value = 'FICO', 1:5)
df %>% filter(p %in% c(-10,0,25,50,75,100), race == "mu") %>% select(FICO)
theme_set(theme_minimal())
ggplot(data = df, aes(x=p, y = FICO))+
geom_line(aes(color = race),size = 1)+
scale_color_manual(values=c("deepskyblue4", "firebrick2","lightseagreen","coral",'black'))+
ggtitle(paste("Def rate = ", def.limit, "\n", mu_type ))+
ylab('Approval %')
out
df %>% filter(p %in% c(-10,0,25,50,75,100), race == "mu") %>% select(FICO)
df %>% filter(p %in% c(-20,0,25,50,75,100), race == "mu") %>% select(FICO)
race_means = c('g1'=660, 'g2'=620, 'g3'=580, 'g4'=540) #low diff
mu_type = 'LOW: g1:660, g2:620, g3:580, g4:540 (SD:200)'
# default-rate for fico
def_rate_fico = function(x){(1-1/(1+exp(-.016*(x-550))))}
# default rate for threshold, mu, sd
default_rate = function(threshold, m, s){
integrate(function(x){
dtnorm(x,m,s)*def_rate_fico(x)
},
threshold,850)$val
}
# total default rate with baserates
default_rate_total = function(thresholds){
dr = purrr::pmap_dbl(data.frame(threshold = thresholds, m = race_means, s = race_sds),
default_rate)
sum(dr*race_rates)/sum(race_rates) # in case we dont have it sum to 1
}
# find constant thresholds
find.constant.thresholds = function(def.limit){
t = uniroot(function(t){
default_rate_total(rep(t, 4))-def.limit
},
lower=300,
upper=850)$root
rep(t, 4)
}
# find constant conditional probability
find.equal.thresholds = function(def.limit){
p = uniroot(function(p){
default_rate_total(qnorm(1-p, race_means, race_sds))-def.limit},
lower=0.001,
upper=0.999)$root
qnorm(1-p, race_means, race_sds)
}
# find threshold for interpolated p
thresholds_p1 = find.equal.thresholds(def.limit)
deltas = thresholds_p1 - mean(thresholds_p1)
find.interp.thresholds = function(p, def.limit){
mu = uniroot(function(mu){
thresholds = deltas*p + mu
default_rate_total(thresholds)-def.limit
}, lower=300,
upper=850)$root
mu+deltas*p
}
#Find approval percent
slider_start = -30
slider_end = slider_start+170
p_list = seq(slider_start, slider_end, by = 1)
out = matrix(ncol = length(find.interp.thresholds(0.5, def.limit)),
nrow = length(p_list))
for (p in p_list){
for(i in 1:length(race_means))
out[(p-(slider_start-1)),i] = round((1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))*100,0)
#out[p+1,i] = (1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))
}
df = data.frame(out)
df$mu = rowMeans(df[,1:4])
colnames(df) = c('g1','g2','g3','g4', 'mu')
df$tradeoff = mu_type
df$p = p_list
out.json = toJSON(df, pretty = T)
write(out.json, "./FICOTest.json")
df = df %>% gather(key = 'race', value = 'FICO', 1:5)
df %>% filter(p %in% c(-20,0,25,50,75,100), race == "mu") %>% select(FICO)
theme_set(theme_minimal())
ggplot(data = df, aes(x=p, y = FICO))+
geom_line(aes(color = race),size = 1)+
scale_color_manual(values=c("deepskyblue4", "firebrick2","lightseagreen","coral",'black'))+
ggtitle(paste("Def rate = ", def.limit, "\n", mu_type ))+
ylab('Approval %')
def.limit = 0.05
# base_rates
race_rates = c('g1'=0.25, 'g2'=0.25, 'g3'=0.25, 'g4'=0.25) #equal base rates
race_means = c('g1'=800, 'g2'=633, 'g3'=567, 'g4'=400) #med diff
mu_type = 'MED: g1:800, g2:633, g3:567, g4:400 (SD:200)'
# pdf of fico score given the fico truncation.
dtnorm = function(x, m, s){
dnorm(x, m, s) / (pnorm(850, m, s) - pnorm(300, m, s))
}
# default-rate for fico
def_rate_fico = function(x){(1-1/(1+exp(-.016*(x-550))))}
# default rate for threshold, mu, sd
default_rate = function(threshold, m, s){
integrate(function(x){
dtnorm(x,m,s)*def_rate_fico(x)
},
threshold,850)$val
}
# total default rate with baserates
default_rate_total = function(thresholds){
dr = purrr::pmap_dbl(data.frame(threshold = thresholds, m = race_means, s = race_sds),
default_rate)
sum(dr*race_rates)/sum(race_rates) # in case we dont have it sum to 1
}
# find constant thresholds
find.constant.thresholds = function(def.limit){
t = uniroot(function(t){
default_rate_total(rep(t, 4))-def.limit
},
lower=300,
upper=850)$root
rep(t, 4)
}
# find constant conditional probability
find.equal.thresholds = function(def.limit){
p = uniroot(function(p){
default_rate_total(qnorm(1-p, race_means, race_sds))-def.limit},
lower=0.001,
upper=0.999)$root
qnorm(1-p, race_means, race_sds)
}
# find threshold for interpolated p
thresholds_p1 = find.equal.thresholds(def.limit)
deltas = thresholds_p1 - mean(thresholds_p1)
find.interp.thresholds = function(p, def.limit){
mu = uniroot(function(mu){
thresholds = deltas*p + mu
default_rate_total(thresholds)-def.limit
}, lower=300,
upper=850)$root
mu+deltas*p
}
#Find approval percent
slider_start = -30
slider_end = slider_start+170
p_list = seq(slider_start, slider_end, by = 1)
out = matrix(ncol = length(find.interp.thresholds(0.5, def.limit)),
nrow = length(p_list))
for (p in p_list){
for(i in 1:length(race_means))
out[(p-(slider_start-1)),i] = round((1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))*100,0)
#out[p+1,i] = (1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))
}
df = data.frame(out)
df$mu = rowMeans(df[,1:4])
colnames(df) = c('g1','g2','g3','g4', 'mu')
df$tradeoff = mu_type
df$p = p_list
out.json = toJSON(df, pretty = T)
write(out.json, "./FICOTest.json")
df = df %>% gather(key = 'race', value = 'FICO', 1:5)
df %>% filter(p %in% c(-20,0,25,50,75,100), race == "mu") %>% select(FICO)
theme_set(theme_minimal())
ggplot(data = df, aes(x=p, y = FICO))+
geom_line(aes(color = race),size = 1)+
scale_color_manual(values=c("deepskyblue4", "firebrick2","lightseagreen","coral",'black'))+
ggtitle(paste("Def rate = ", def.limit, "\n", mu_type ))+
ylab('Approval %')
race_means = c('g1'=920, 'g2'=707, 'g3'=493, 'g4'=280) #high diff
mu_type = 'HIGH: g1:920, g2:707, g3:493, g4:280 (SD = 200)'
race_sds = c('g1'=200, 'g2'=200, 'g3'=200, 'g4'=200)
# pdf of fico score given the fico truncation.
dtnorm = function(x, m, s){
dnorm(x, m, s) / (pnorm(850, m, s) - pnorm(300, m, s))
}
# default-rate for fico
def_rate_fico = function(x){(1-1/(1+exp(-.016*(x-550))))}
# default rate for threshold, mu, sd
default_rate = function(threshold, m, s){
integrate(function(x){
dtnorm(x,m,s)*def_rate_fico(x)
},
threshold,850)$val
}
# total default rate with baserates
default_rate_total = function(thresholds){
dr = purrr::pmap_dbl(data.frame(threshold = thresholds, m = race_means, s = race_sds),
default_rate)
sum(dr*race_rates)/sum(race_rates) # in case we dont have it sum to 1
}
# find constant thresholds
find.constant.thresholds = function(def.limit){
t = uniroot(function(t){
default_rate_total(rep(t, 4))-def.limit
},
lower=300,
upper=850)$root
rep(t, 4)
}
# find constant conditional probability
find.equal.thresholds = function(def.limit){
p = uniroot(function(p){
default_rate_total(qnorm(1-p, race_means, race_sds))-def.limit},
lower=0.001,
upper=0.999)$root
qnorm(1-p, race_means, race_sds)
}
# find threshold for interpolated p
thresholds_p1 = find.equal.thresholds(def.limit)
deltas = thresholds_p1 - mean(thresholds_p1)
find.interp.thresholds = function(p, def.limit){
mu = uniroot(function(mu){
thresholds = deltas*p + mu
default_rate_total(thresholds)-def.limit
}, lower=300,
upper=850)$root
mu+deltas*p
}
#Find approval percent
slider_start = -30
slider_end = slider_start+170
p_list = seq(slider_start, slider_end, by = 1)
out = matrix(ncol = length(find.interp.thresholds(0.5, def.limit)),
nrow = length(p_list))
for (p in p_list){
for(i in 1:length(race_means))
out[(p-(slider_start-1)),i] = round((1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))*100,0)
#out[p+1,i] = (1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))
}
df = data.frame(out)
df$mu = rowMeans(df[,1:4])
colnames(df) = c('g1','g2','g3','g4', 'mu')
df$tradeoff = mu_type
df$p = p_list
out.json = toJSON(df, pretty = T)
write(out.json, "./FICOTest.json")
df = df %>% gather(key = 'race', value = 'FICO', 1:5)
df %>% filter(p %in% c(-20,0,25,50,75,100), race == "mu") %>% select(FICO)
theme_set(theme_minimal())
ggplot(data = df, aes(x=p, y = FICO))+
geom_line(aes(color = race),size = 1)+
scale_color_manual(values=c("deepskyblue4", "firebrick2","lightseagreen","coral",'black'))+
ggtitle(paste("Def rate = ", def.limit, "\n", mu_type ))+
ylab('Approval %')
def.limit = 0.1
race_means = c('g1'=920, 'g2'=707, 'g3'=493, 'g4'=280) #high diff
mu_type = 'HIGH: g1:920, g2:707, g3:493, g4:280 (SD = 200)'
race_sds = c('g1'=200, 'g2'=200, 'g3'=200, 'g4'=200)
# pdf of fico score given the fico truncation.
dtnorm = function(x, m, s){
dnorm(x, m, s) / (pnorm(850, m, s) - pnorm(300, m, s))
}
# default-rate for fico
def_rate_fico = function(x){(1-1/(1+exp(-.016*(x-550))))}
# default rate for threshold, mu, sd
default_rate = function(threshold, m, s){
integrate(function(x){
dtnorm(x,m,s)*def_rate_fico(x)
},
threshold,850)$val
}
# total default rate with baserates
default_rate_total = function(thresholds){
dr = purrr::pmap_dbl(data.frame(threshold = thresholds, m = race_means, s = race_sds),
default_rate)
sum(dr*race_rates)/sum(race_rates) # in case we dont have it sum to 1
}
# find constant thresholds
find.constant.thresholds = function(def.limit){
t = uniroot(function(t){
default_rate_total(rep(t, 4))-def.limit
},
lower=300,
upper=850)$root
rep(t, 4)
}
# find constant conditional probability
find.equal.thresholds = function(def.limit){
p = uniroot(function(p){
default_rate_total(qnorm(1-p, race_means, race_sds))-def.limit},
lower=0.001,
upper=0.999)$root
qnorm(1-p, race_means, race_sds)
}
# find threshold for interpolated p
thresholds_p1 = find.equal.thresholds(def.limit)
deltas = thresholds_p1 - mean(thresholds_p1)
find.interp.thresholds = function(p, def.limit){
mu = uniroot(function(mu){
thresholds = deltas*p + mu
default_rate_total(thresholds)-def.limit
}, lower=300,
upper=850)$root
mu+deltas*p
}
#Find approval percent
slider_start = -30
slider_end = slider_start+170
p_list = seq(slider_start, slider_end, by = 1)
out = matrix(ncol = length(find.interp.thresholds(0.5, def.limit)),
nrow = length(p_list))
for (p in p_list){
for(i in 1:length(race_means))
out[(p-(slider_start-1)),i] = round((1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))*100,0)
#out[p+1,i] = (1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))
}
df = data.frame(out)
df$mu = rowMeans(df[,1:4])
colnames(df) = c('g1','g2','g3','g4', 'mu')
df$tradeoff = mu_type
df$p = p_list
out.json = toJSON(df, pretty = T)
write(out.json, "./FICOTest.json")
df = df %>% gather(key = 'race', value = 'FICO', 1:5)
df %>% filter(p %in% c(-20,0,25,50,75,100), race == "mu") %>% select(FICO)
theme_set(theme_minimal())
ggplot(data = df, aes(x=p, y = FICO))+
geom_line(aes(color = race),size = 1)+
scale_color_manual(values=c("deepskyblue4", "firebrick2","lightseagreen","coral",'black'))+
ggtitle(paste("Def rate = ", def.limit, "\n", mu_type ))+
ylab('Approval %')
library(jsonlite)
library(tidyverse)
#Read in and merge all json data files
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
setwd("./data")
file_list = list.files()
# setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# setwd("./dataV3V4combined")
# file_list = list.files()
for (file in file_list){
print(file)
# if the merged dataset doesn't exist, create it
if (!exists("df_full")){
json.data = fromJSON(file)
df_full = data.frame(json.data[["trials"]][["response"]],
json.data[["trials"]][["att"]],
json.data[["trials"]][["trialNumber"]],
json.data[["trials"]][["prompt"]],
json.data[["trials"]][["chosenData"]][["g1"]],
json.data[["trials"]][["chosenData"]][["g2"]],
json.data[["trials"]][["chosenData"]][["g3"]],
json.data[["trials"]][["chosenData"]][["g4"]],
json.data[["trials"]][["chosenData"]][["mu"]],
json.data[["trials"]][["chosenData"]][["tradeoff"]],
json.data[["trials"]][["chosenData"]][["p"]],
json.data[["trials"]][["jitter"]],
json.data[["subjectData"]][["promptCheck1"]],
json.data[["subjectData"]][["promptCheck2"]])
df_full$id = json.data[["client"]][["sid"]]
}
# if the merged dataset does exist, append to it
if (exists("df_full")){
json.data = fromJSON(file)
temp_dataset = data.frame(json.data[["trials"]][["response"]],
json.data[["trials"]][["att"]],
json.data[["trials"]][["trialNumber"]],
json.data[["trials"]][["prompt"]],
json.data[["trials"]][["chosenData"]][["g1"]],
json.data[["trials"]][["chosenData"]][["g2"]],
json.data[["trials"]][["chosenData"]][["g3"]],
json.data[["trials"]][["chosenData"]][["g4"]],
json.data[["trials"]][["chosenData"]][["mu"]],
json.data[["trials"]][["chosenData"]][["tradeoff"]],
json.data[["trials"]][["chosenData"]][["p"]],
json.data[["trials"]][["jitter"]],
json.data[["subjectData"]][["promptCheck1"]],
json.data[["subjectData"]][["promptCheck2"]])
temp_dataset$id = json.data[["client"]][["sid"]]
df_full = rbind(df_full, temp_dataset)
rm(temp_dataset)
}
}
df = df_full %>% distinct()
colnames(df) = c("response","att", "trialNumber", "prompt", "g1","g2","g3","g4", "mu", "tradeoff", "p", "jitter","check1", "check2", "id")
df$response = as.numeric(as.character(df$response))
#variance of response
df = df %>%
mutate(var = pmap_dbl(list(g1,g2,g3,g4), ~ var(c(...))))
df$sd = sqrt(df$var)
#attention checks
df30 = df %>% select(att, p, id, trialNumber) %>%  filter(att == 1, trialNumber ==5)
df30$diff = abs(df30$p-30)
df60 = df %>% select(att, p, id, trialNumber) %>%  filter(att == 1, trialNumber ==25)
df60$diff = abs(df60$p-60)
table(df30$diff)
ggplot(df30, aes(diff)) +
geom_histogram(bins = 15)
#dataframe manipulation (can be done on group df)
df$prompt.type <- ifelse(grepl("loan", df$prompt, ignore.case = T), "loan",
ifelse(grepl("newspaper", df$prompt, ignore.case = T), "newspaper",
ifelse(grepl("bail", df$prompt, ignore.case = T), "bail",
ifelse(grepl("job", df$prompt, ignore.case = T), "job",
ifelse(grepl("meals", df$prompt, ignore.case = T), "meals",
ifelse(grepl("respirator", df$prompt, ignore.case = T), "respirator","Other"))))))
df$tradeoff <- ifelse(grepl("LOW", df$tradeoff, ignore.case = T), "low",
ifelse(grepl("MED", df$tradeoff, ignore.case = T), "med","high"))
##remove attention trials
df = df %>%
filter(att == 0)
#plots of response by datatype and prompt
library(ggpubr)
df %>% mutate(name = fct_relevel(tradeoff,
"low",
"med",
"high")) %>%
ggerrorplot(x = "name", y = "p",
desc_stat = "mean_se")+
ggtitle("latentEquality Distribution by Tradeoff")
df %>% mutate(name = fct_relevel(prompt.type,
"loan",
"bail",
"job",
"newspaper",
"meals",
"respirator")) %>%
ggerrorplot(x = "name", y = "p",
desc_stat = "mean_se")+
ggtitle("latentEquality Distribution by Prompt")
df %>% mutate(tradeoff = fct_relevel(tradeoff,
"low",
"med",
"high"),
prompt = fct_relevel(prompt.type,
"loan",
"bail",
"job",
"newspaper",
"meals",
"respirator")) %>%
ggerrorplot(x = "prompt", y = "p",
desc_stat = "mean_se") +
facet_grid(.~tradeoff)+
theme(axis.text.x = element_text(angle = 90))+
ggtitle("latentEquality by Prompt and Tradeoff")
#Distribution of responses
df %>% mutate(name = fct_relevel(tradeoff,
"low",
"med",
"high")) %>% ggplot(aes(p)) +
geom_histogram(bins = 15) +facet_grid(.~name)
ggplot(df, aes(x = trialNumber, y = p))+
geom_point()+
facet_grid(.~tradeoff)+
geom_smooth(method = "lm")
#Mu vs variance
ggplot(df, aes(x = mu, y = sd, color = tradeoff))+
geom_point()+
facet_grid(.~tradeoff)+
geom_smooth()
lin = lm(data = df, p ~ tradeoff+prompt.type+jitter)
summary(lin)
##Create DF to compare correlation between trials
df_first_obs = df %>%
arrange(trialNumber) %>%
group_by(id, prompt.type, tradeoff) %>%
slice(1) %>%
select(id, tradeoff, prompt.type, mu, response, p)
df_second_obs = df %>% arrange(trialNumber) %>%
group_by(id, prompt.type, tradeoff) %>% slice(n()) %>%
select(id, tradeoff, prompt.type, mu, response, p)
df_grouped = left_join(df_first_obs, df_second_obs, by=c("id","tradeoff", "prompt.type")) %>% rowwise()
#labels = data.frame(x = 25, y = 55, label = corr_eqn(df_grouped$mu.x, df_grouped$mu.y))
ggplot(df_grouped, aes(x = p.x, y = p.y))+
geom_point()+
facet_grid(.~tradeoff)+
ggtitle("Correlation of LatentEquality (repeated trials) within subject")+
xlab("Response (first trial)") +
ylab("Reponse (second trial)") +
geom_smooth(method = "lm")
cor(df_grouped$p.x,df_grouped$p.y)
