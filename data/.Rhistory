ifelse(grepl("MED", df$tradeoff, ignore.case = T), "med","high"))
df = df %>% mutate(tradeoff = fct_relevel(tradeoff,
"low",
"med",
"high"))
df = df %>%
filter(att == 0)
glimpse(df)
df_chi = df %>% select(tradeoff, p)
df_chi = df_chi %>% mutate(ef = as.integer((df$p > -20 & df$p < 20)))
df_chi = df_chi %>% mutate(eq = as.integer((df$p > 80 & df$p < 120)))
df_chi = df_chi %>% mutate(tf = as.integer((df$p > 20 & df$p < 80)))
glimpse(df_chi)
df_chi = df_chi %>%
mutate(strategy  = case_when(
.$p > -20 & .$p< 20 ~ "efficiency",
.$p > 80 & .$p< 120 ~ "equality",
$p < 80 & .$p > 20 ~ "tradeoff",
))
df_chi = df %>% select(tradeoff, p)
df_chi = df_chi %>%
mutate(strategy  = case_when(
.$p > -20 & .$p< 20 ~ "efficiency",
.$p > 80 & .$p< 120 ~ "equality",
$p < 80 & .$p > 20 ~ "tradeoff",
))
df_chi = df_chi %>%
mutate(strategy  = case_when(
.$p > -20 & .$p< 20 ~ "efficiency",
.$p > 80 & .$p< 120 ~ "equality",
$p < 80 & .$p > 20 ~ "tradeoff",
))
df_chi = df_chi %>%
mutate(strategy  = case_when(
p > -20 & p< 20 ~ "efficiency",
p > 80 & p< 120 ~ "equality",
p < 80 & p > 20 ~ "tradeoff",
))
glimpse(df_chi)
tbl = table(df_chi$tradeoff, df_chi$strategy)
tbl
chisq.test(tbl)
length(df_chi$p)
library(jsonlite)
library(tidyverse)
#json.data = fromJSON("./sona-31385.json")
#Read in and merge all json data files
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
setwd("./data")
file_list = list.files()
# setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# setwd("./dataV3V4combined")
# file_list = list.files()
for (file in file_list){
print(file)
# if the merged dataset doesn't exist, create it
if (!exists("df_full")){
json.data = fromJSON(file)
df_full = data.frame(json.data[["trials"]][["response"]],
json.data[["trials"]][["att"]],
json.data[["trials"]][["trialNumber"]],
json.data[["trials"]][["prompt"]],
json.data[["trials"]][["chosenData"]][["g1"]],
json.data[["trials"]][["chosenData"]][["g2"]],
json.data[["trials"]][["chosenData"]][["g3"]],
json.data[["trials"]][["chosenData"]][["g4"]],
json.data[["trials"]][["chosenData"]][["mu"]],
json.data[["trials"]][["chosenData"]][["tradeoff"]],
json.data[["trials"]][["chosenData"]][["p"]],
json.data[["trials"]][["jitter"]],
json.data[["subjectData"]][["promptCheck1"]],
json.data[["subjectData"]][["promptCheck2"]])
df_full$id = json.data[["client"]][["sid"]]
}
# if the merged dataset does exist, append to it
if (exists("df_full")){
json.data = fromJSON(file)
temp_dataset = data.frame(json.data[["trials"]][["response"]],
json.data[["trials"]][["att"]],
json.data[["trials"]][["trialNumber"]],
json.data[["trials"]][["prompt"]],
json.data[["trials"]][["chosenData"]][["g1"]],
json.data[["trials"]][["chosenData"]][["g2"]],
json.data[["trials"]][["chosenData"]][["g3"]],
json.data[["trials"]][["chosenData"]][["g4"]],
json.data[["trials"]][["chosenData"]][["mu"]],
json.data[["trials"]][["chosenData"]][["tradeoff"]],
json.data[["trials"]][["chosenData"]][["p"]],
json.data[["trials"]][["jitter"]],
json.data[["subjectData"]][["promptCheck1"]],
json.data[["subjectData"]][["promptCheck2"]])
temp_dataset$id = json.data[["client"]][["sid"]]
df_full = rbind(df_full, temp_dataset)
rm(temp_dataset)
}
}
df = df_full %>% distinct()
colnames(df) = c("response","att", "trialNumber", "prompt", "g1","g2","g3","g4", "mu", "tradeoff", "p", "jitter","check1", "check2", "id")
df$response = as.numeric(as.character(df$response))
#variance of response
df = df %>%
mutate(var = pmap_dbl(list(g1,g2,g3,g4), ~ var(c(...))))
df$sd = sqrt(df$var)
#attention checks
df30 = df %>% select(att, p, id, trialNumber) %>%  filter(att == 1, trialNumber ==5)
df30$diff = abs(df30$p-30)
df60 = df %>% select(att, p, id, trialNumber) %>%  filter(att == 1, trialNumber ==25)
df60$diff = abs(df60$p-60)
table(df30$diff)
ggplot(df30, aes(diff)) +
geom_histogram(bins = 15)
# includeID60 = df60[df60$diff<=10,"id"]
# includeID30 = df30[df30$diff<=10,"id"]
#
# df = df %>% filter(id %in% c(includeID60,includeID30) )
#df = df %>% filter(check1+check2 >0)
#dataframe manipulation (can be done on group df)
df$prompt.type <- ifelse(grepl("loan", df$prompt, ignore.case = T), "loan",
ifelse(grepl("newspaper", df$prompt, ignore.case = T), "newspaper",
ifelse(grepl("bail", df$prompt, ignore.case = T), "bail",
ifelse(grepl("job", df$prompt, ignore.case = T), "job",
ifelse(grepl("meals", df$prompt, ignore.case = T), "meals",
ifelse(grepl("respirator", df$prompt, ignore.case = T), "respirator","Other"))))))
df$tradeoff <- ifelse(grepl("LOW", df$tradeoff, ignore.case = T), "low",
ifelse(grepl("MED", df$tradeoff, ignore.case = T), "med","high"))
df = df %>% mutate(tradeoff = fct_relevel(tradeoff,
"low",
"med",
"high"))
#df$respJitter = df$response+df$jitter
#df$latentEquality = df$response+df$jitter-50
##remove attention trials
df = df %>%
filter(att == 0)
df %>% group_by(tradeoff) %>% summarise(round(max(mu),0))
df %>% group_by(tradeoff) %>%
filter(round(mu,0) == round(max(mu),0))%>%
filter( p == min(p) | p == max(p)) %>% filter(tradeoff == 'low') %>%
select(p, mu)
df %>% group_by(tradeoff) %>% summarise(mean(p))
#plots of response by datatype and prompt
library(ggpubr)
ggerrorplot(df, x = "tradeoff", y = "p",
desc_stat = "mean_se", size  =1)+
theme(text = element_text(size=20))+
xlab("Tradeoff Type")+
ylab("Equality Index")
df %>% mutate(name = fct_relevel(prompt.type,
"loan",
"bail",
"job",
"newspaper",
"meals",
"respirator")) %>%
ggerrorplot(x = "name", y = "p",
desc_stat = "mean_se", size  =1)+
theme(text = element_text(size=20), axis.text.x = element_text(size = 20))+
xlab("Prompt")+
ylab("Equality Index")
ggerrorplot(df, x = "tradeoff", y = "p",
desc_stat = "mean_se", size  =1)+
theme(text = element_text(size=20))+
xlab("Tradeoff Type")+
ylab("Equality Index")+ ylim(0,100)
#######################
#Define known values:
#######################
library(tidyverse)
library(patchwork)
library(jsonlite)
def.limit = 0.1
# base_rates
race_rates = c('g1'=0.25, 'g2'=0.25, 'g3'=0.25, 'g4'=0.25) #equal base rates
# # means
race_means = c('g1'=660, 'g2'=620, 'g3'=580, 'g4'=540) #low diff
mu_type = 'LOW: g1:660, g2:620, g3:580, g4:540 (SD:336)'
# race_means = c('g1'=660, 'g2'=620, 'g3'=580, 'g4'=540) #low diff
# mu_type = 'LOW: g1:660, g2:620, g3:580, g4:540 (SD:200)'
# race_means = c('g1'=800, 'g2'=633, 'g3'=567, 'g4'=400) #med diff
# mu_type = 'MED: g1:800, g2:633, g3:567, g4:400 (SD:200)'
# race_means = c('g1'=920, 'g2'=707, 'g3'=493, 'g4'=280) #high diff
# mu_type = 'HIGH: g1:920, g2:707, g3:493, g4:280 (SD = 200)'
# race_sds = c('g1'=200, 'g2'=200, 'g3'=200, 'g4'=200)
# pdf of fico score given the fico truncation.
dtnorm = function(x, m, s){
dnorm(x, m, s) / (pnorm(850, m, s) - pnorm(300, m, s))
}
# default-rate for fico
def_rate_fico = function(x){(1-1/(1+exp(-.016*(x-550))))}
# default rate for threshold, mu, sd
default_rate = function(threshold, m, s){
integrate(function(x){
dtnorm(x,m,s)*def_rate_fico(x)
},
threshold,850)$val
}
# total default rate with baserates
default_rate_total = function(thresholds){
dr = purrr::pmap_dbl(data.frame(threshold = thresholds, m = race_means, s = race_sds),
default_rate)
sum(dr*race_rates)/sum(race_rates) # in case we dont have it sum to 1
}
# find constant thresholds
find.constant.thresholds = function(def.limit){
t = uniroot(function(t){
default_rate_total(rep(t, 4))-def.limit
},
lower=300,
upper=850)$root
rep(t, 4)
}
# find constant conditional probability
find.equal.thresholds = function(def.limit){
p = uniroot(function(p){
default_rate_total(qnorm(1-p, race_means, race_sds))-def.limit},
lower=0.001,
upper=0.999)$root
qnorm(1-p, race_means, race_sds)
}
# find threshold for interpolated p
thresholds_p1 = find.equal.thresholds(def.limit)
deltas = thresholds_p1 - mean(thresholds_p1)
find.interp.thresholds = function(p, def.limit){
mu = uniroot(function(mu){
thresholds = deltas*p + mu
default_rate_total(thresholds)-def.limit
}, lower=300,
upper=850)$root
mu+deltas*p
}
#Find approval percent
slider_start = -30
slider_end = slider_start+170
p_list = seq(slider_start, slider_end, by = 1)
out = matrix(ncol = length(find.interp.thresholds(0.5, def.limit)),
nrow = length(p_list))
for (p in p_list){
for(i in 1:length(race_means))
out[(p-(slider_start-1)),i] = (1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))*100
#out[p+1,i] = (1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))
}
df = data.frame(out)
df$mu = rowMeans(df[,1:4])
colnames(df) = c('g1','g2','g3','g4', 'mu')
df = df %>%
mutate(var = pmap_dbl(list(g1,g2,g3,g4), ~ var(c(...))))
df$tradeoff = mu_type
#######################
#Define known values:
#######################
library(tidyverse)
library(patchwork)
library(jsonlite)
def.limit = 0.1
# base_rates
race_rates = c('g1'=0.25, 'g2'=0.25, 'g3'=0.25, 'g4'=0.25) #equal base rates
race_means = c('g1'=660, 'g2'=620, 'g3'=580, 'g4'=540) #low diff
mu_type = 'LOW: g1:660, g2:620, g3:580, g4:540 (SD:200)'
race_means = c('g1'=800, 'g2'=633, 'g3'=567, 'g4'=400) #med diff
mu_type = 'MED: g1:800, g2:633, g3:567, g4:400 (SD:200)'
race_means = c('g1'=920, 'g2'=707, 'g3'=493, 'g4'=280) #high diff
mu_type = 'HIGH: g1:920, g2:707, g3:493, g4:280 (SD = 200)'
race_sds = c('g1'=200, 'g2'=200, 'g3'=200, 'g4'=200)
# pdf of fico score given the fico truncation.
dtnorm = function(x, m, s){
dnorm(x, m, s) / (pnorm(850, m, s) - pnorm(300, m, s))
}
# default-rate for fico
def_rate_fico = function(x){(1-1/(1+exp(-.016*(x-550))))}
# default rate for threshold, mu, sd
default_rate = function(threshold, m, s){
integrate(function(x){
dtnorm(x,m,s)*def_rate_fico(x)
},
threshold,850)$val
}
# total default rate with baserates
default_rate_total = function(thresholds){
dr = purrr::pmap_dbl(data.frame(threshold = thresholds, m = race_means, s = race_sds),
default_rate)
sum(dr*race_rates)/sum(race_rates) # in case we dont have it sum to 1
}
# find constant thresholds
find.constant.thresholds = function(def.limit){
t = uniroot(function(t){
default_rate_total(rep(t, 4))-def.limit
},
lower=300,
upper=850)$root
rep(t, 4)
}
# find constant conditional probability
find.equal.thresholds = function(def.limit){
p = uniroot(function(p){
default_rate_total(qnorm(1-p, race_means, race_sds))-def.limit},
lower=0.001,
upper=0.999)$root
qnorm(1-p, race_means, race_sds)
}
# find threshold for interpolated p
thresholds_p1 = find.equal.thresholds(def.limit)
deltas = thresholds_p1 - mean(thresholds_p1)
find.interp.thresholds = function(p, def.limit){
mu = uniroot(function(mu){
thresholds = deltas*p + mu
default_rate_total(thresholds)-def.limit
}, lower=300,
upper=850)$root
mu+deltas*p
}
#Find approval percent
slider_start = -30
slider_end = slider_start+170
p_list = seq(slider_start, slider_end, by = 1)
out = matrix(ncol = length(find.interp.thresholds(0.5, def.limit)),
nrow = length(p_list))
for (p in p_list){
for(i in 1:length(race_means))
out[(p-(slider_start-1)),i] = (1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))*100
#out[p+1,i] = (1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))
}
df = data.frame(out)
df$mu = rowMeans(df[,1:4])
colnames(df) = c('g1','g2','g3','g4', 'mu')
df$tradeoff = mu_type
df$p = p_list
out.json = toJSON(df, pretty = T)
write(out.json, "./FICOTest.json")
df = df %>% gather(key = 'Group', value = 'FICO', 1:5)
df %>% filter(p %in% c(62), Group == "mu") %>% select(FICO)
theme_set(theme_minimal())
ggplot(data = df, aes(x=p, y = FICO))+
geom_line(aes(color = Group),size = 2)+
scale_color_manual(values=c("deepskyblue4", "firebrick2","lightseagreen","coral",'black'))+
#ggtitle(paste("Def rate = ", def.limit, "\n", mu_type ))+
theme(text = element_text(size=40))+
ylab('Approval %')+
xlab("Equality Index")+
ylim(0,100)
ggplot(data = df, aes(x=p, y = FICO))+
geom_line(aes(color = Group),size = 2)+
scale_color_manual(values=c("deepskyblue4", "firebrick2","lightseagreen","coral",'black'))+
#ggtitle(paste("Def rate = ", def.limit, "\n", mu_type ))+
theme(text = element_text(size=40))+
ylab('Approval %')+
xlab("Equality Index")+
ylim(0,100)+ xlim(0,100)
race_means = c('g1'=800, 'g2'=633, 'g3'=567, 'g4'=400) #med diff
mu_type = 'MED: g1:800, g2:633, g3:567, g4:400 (SD:200)'
# pdf of fico score given the fico truncation.
dtnorm = function(x, m, s){
dnorm(x, m, s) / (pnorm(850, m, s) - pnorm(300, m, s))
}
# default-rate for fico
def_rate_fico = function(x){(1-1/(1+exp(-.016*(x-550))))}
# default rate for threshold, mu, sd
default_rate = function(threshold, m, s){
integrate(function(x){
dtnorm(x,m,s)*def_rate_fico(x)
},
threshold,850)$val
}
# total default rate with baserates
default_rate_total = function(thresholds){
dr = purrr::pmap_dbl(data.frame(threshold = thresholds, m = race_means, s = race_sds),
default_rate)
sum(dr*race_rates)/sum(race_rates) # in case we dont have it sum to 1
}
# find constant thresholds
find.constant.thresholds = function(def.limit){
t = uniroot(function(t){
default_rate_total(rep(t, 4))-def.limit
},
lower=300,
upper=850)$root
rep(t, 4)
}
# find constant conditional probability
find.equal.thresholds = function(def.limit){
p = uniroot(function(p){
default_rate_total(qnorm(1-p, race_means, race_sds))-def.limit},
lower=0.001,
upper=0.999)$root
qnorm(1-p, race_means, race_sds)
}
# find threshold for interpolated p
thresholds_p1 = find.equal.thresholds(def.limit)
deltas = thresholds_p1 - mean(thresholds_p1)
find.interp.thresholds = function(p, def.limit){
mu = uniroot(function(mu){
thresholds = deltas*p + mu
default_rate_total(thresholds)-def.limit
}, lower=300,
upper=850)$root
mu+deltas*p
}
#Find approval percent
slider_start = -30
slider_end = slider_start+170
p_list = seq(slider_start, slider_end, by = 1)
out = matrix(ncol = length(find.interp.thresholds(0.5, def.limit)),
nrow = length(p_list))
for (p in p_list){
for(i in 1:length(race_means))
out[(p-(slider_start-1)),i] = (1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))*100
#out[p+1,i] = (1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))
}
df = data.frame(out)
df$mu = rowMeans(df[,1:4])
colnames(df) = c('g1','g2','g3','g4', 'mu')
df$tradeoff = mu_type
df$p = p_list
out.json = toJSON(df, pretty = T)
write(out.json, "./FICOTest.json")
df = df %>% gather(key = 'Group', value = 'FICO', 1:5)
df %>% filter(p %in% c(62), Group == "mu") %>% select(FICO)
theme_set(theme_minimal())
ggplot(data = df, aes(x=p, y = FICO))+
geom_line(aes(color = Group),size = 2)+
scale_color_manual(values=c("deepskyblue4", "firebrick2","lightseagreen","coral",'black'))+
#ggtitle(paste("Def rate = ", def.limit, "\n", mu_type ))+
theme(text = element_text(size=40))+
ylab('Approval %')+
xlab("Equality Index")+
ylim(0,100)+ xlim(0,100)
#######################
#Define known values:
#######################
library(tidyverse)
library(patchwork)
library(jsonlite)
def.limit = 0.1
# base_rates
race_rates = c('g1'=0.25, 'g2'=0.25, 'g3'=0.25, 'g4'=0.25) #equal base rates
race_means = c('g1'=660, 'g2'=620, 'g3'=580, 'g4'=540) #low diff
mu_type = 'LOW: g1:660, g2:620, g3:580, g4:540 (SD:200)'
# pdf of fico score given the fico truncation.
dtnorm = function(x, m, s){
dnorm(x, m, s) / (pnorm(850, m, s) - pnorm(300, m, s))
}
# default-rate for fico
def_rate_fico = function(x){(1-1/(1+exp(-.016*(x-550))))}
# default rate for threshold, mu, sd
default_rate = function(threshold, m, s){
integrate(function(x){
dtnorm(x,m,s)*def_rate_fico(x)
},
threshold,850)$val
}
# total default rate with baserates
default_rate_total = function(thresholds){
dr = purrr::pmap_dbl(data.frame(threshold = thresholds, m = race_means, s = race_sds),
default_rate)
sum(dr*race_rates)/sum(race_rates) # in case we dont have it sum to 1
}
# find constant thresholds
find.constant.thresholds = function(def.limit){
t = uniroot(function(t){
default_rate_total(rep(t, 4))-def.limit
},
lower=300,
upper=850)$root
rep(t, 4)
}
# find constant conditional probability
find.equal.thresholds = function(def.limit){
p = uniroot(function(p){
default_rate_total(qnorm(1-p, race_means, race_sds))-def.limit},
lower=0.001,
upper=0.999)$root
qnorm(1-p, race_means, race_sds)
}
# find threshold for interpolated p
thresholds_p1 = find.equal.thresholds(def.limit)
deltas = thresholds_p1 - mean(thresholds_p1)
find.interp.thresholds = function(p, def.limit){
mu = uniroot(function(mu){
thresholds = deltas*p + mu
default_rate_total(thresholds)-def.limit
}, lower=300,
upper=850)$root
mu+deltas*p
}
#Find approval percent
slider_start = -30
slider_end = slider_start+170
p_list = seq(slider_start, slider_end, by = 1)
out = matrix(ncol = length(find.interp.thresholds(0.5, def.limit)),
nrow = length(p_list))
for (p in p_list){
for(i in 1:length(race_means))
out[(p-(slider_start-1)),i] = (1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))*100
#out[p+1,i] = (1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))
}
df = data.frame(out)
df$mu = rowMeans(df[,1:4])
colnames(df) = c('g1','g2','g3','g4', 'mu')
df$tradeoff = mu_type
df$p = p_list
out.json = toJSON(df, pretty = T)
write(out.json, "./FICOTest.json")
df = df %>% gather(key = 'Group', value = 'FICO', 1:5)
df %>% filter(p %in% c(62), Group == "mu") %>% select(FICO)
theme_set(theme_minimal())
ggplot(data = df, aes(x=p, y = FICO))+
geom_line(aes(color = Group),size = 2)+
scale_color_manual(values=c("deepskyblue4", "firebrick2","lightseagreen","coral",'black'))+
#ggtitle(paste("Def rate = ", def.limit, "\n", mu_type ))+
theme(text = element_text(size=40))+
ylab('Approval %')+
xlab("Equality Index")+
ylim(0,100)+ xlim(0,100)
